# Core dependencies for Qwen3-4B fine-tuning
torch>=2.1.0
transformers>=4.40.0
datasets>=2.14.0
peft>=0.10.0
accelerate>=0.27.0
deepspeed>=0.13.0

# Utilities
wandb>=0.16.0
rouge-score>=0.1.2

# Flash Attention 2 (requires CUDA 11.8+)
flash-attn>=2.5.0

# Optional but recommended
ninja  # For faster compilation
packaging
